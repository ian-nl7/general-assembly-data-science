{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Time Series Analysis\n",
    "\n",
    "_Authors: Arun Ahuja (NYC)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "\n",
    "- Understand what time series data is and what is unique about it\n",
    "- Identify common elements of time series data\n",
    "- Identify common transformation of time series data\n",
    "- Apply common time series transformations to a dataset using Pandas\n",
    "- Define autocorrelation\n",
    "- Use Pandas to explore autocorrelation\n",
    "- Analyze autocorrelation in a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Opening: Time Series Analysis](#opening-time-series-analysis)\n",
    "- [What is time series data?](#what-is-time-series-data)\n",
    "\t- [Time is always a factor](#time-is-always-a-factor)\n",
    "\t- [However, sometimes time is a key factor](#however-sometimes-time-is-a-key-factor)\n",
    "\t- [Where do we use time series analysis?](#where-do-we-use-time-series-analysis)\n",
    "\t- [Trends and Seasonality](#trends-and-seasonality)\n",
    "\t- [Other time phenomena](#other-time-phenomena)\n",
    "- [Demo: Exploring Rossmann drugstore sales data](#demo-exploring-rossmann-drugstore-sales-data)\n",
    "\t- [Load Dataset and Pre-Process](#load-dataset-and-pre-process)\n",
    "- [Introduction: Common analysis for time series data](#introduction-common-analysis-for-time-series-data)\n",
    "\t- [Aggregating time series](#aggregating-time-series)\n",
    "\t- [Pandas window functions](#pandas-window-functions)\n",
    "\t- [Pandas expanding functions](#pandas-expanding-functions)\n",
    "\t- [Moving Averages](#moving-averages)\n",
    "\t- [Exponential Weighted Moving Averages](#exponential-weighted-moving-averages)\n",
    "- [Autocorrelation](#autocorrelation)\n",
    "\t- [Why can autocorrelation be a problem?](#why-can-autocorrelation-be-a-problem)\n",
    "\t- [How to compute autocorrelation](#how-to-compute-autocorrelation)\n",
    "    - [Partial Autocorrelation](#partial-autocorrelation)\n",
    "- [Exercises](#exercises)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"opening-time-series-analysis\"></a>\n",
    "## Opening: Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this class, we’ll discuss analyzing data that is changing over time.\n",
    "- In most of our previous examples, we didn’t care which data points were collected earlier or later than others.\n",
    "- We made assumptions that the data was not changing over time.\n",
    "- This class will focus on statistics around data that is changing over time and how to measure that change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we will focus on Identifying problems related to time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"what-is-time-series-data\"></a>\n",
    "## What is time series data?\n",
    "Objective: Understand what time series data is and what is unique about it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Time series data is any data where the individual data points change over time.\n",
    "- This is fairly common in sales and other business cases where data would likely change according to seasons and trends.\n",
    "- Time series data is also useful for studying social phenomena. For instance, there is statistically more crime in the summer, which is a seasonal trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"time-is-always-a-factor\"></a>\n",
    "### Time is always a factor\n",
    "\n",
    "Most datasets are likely to have an important time component, but typically we assume that it’s fairly minimal.\n",
    "\n",
    "For example, if we were analyzing salaries in an industry, it’s clear that salaries shift over time and vary with the economic period.\n",
    "\n",
    "However, if we are examining the problem on a smaller scale (e.g. 3-5 years), the effect of time on salaries is much smaller than other factors, like industry or position.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"however-sometimes-time-is-a-key-factor\"></a>\n",
    "### However, sometimes time is a key factor\n",
    "\n",
    "When the time component is important, we need to focus on identifying the aspects of the data that are influenced by time and those that aren’t.\n",
    "\n",
    "Time series data is a sequence of values. We will be interested in studying the changes to this series and how related individual values are.\n",
    "\n",
    "For example, how much does this week’s sales affect next week’s?  How much does today’s stock price affect tomorrow’s?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think about the various datasets we’ve used so far. For each dataset, identify the time components of those datasets.  What time related features might be important to our analysis?**\n",
    "\n",
    "Examples:\n",
    "- Titanic\n",
    "- Bikeshare\n",
    "- Flight Delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"where-do-we-use-time-series-analysis\"></a>\n",
    "### Where do we use time series analysis?\n",
    "\n",
    "- Time series analysis is useful in many fields:  sales analysis, stock market trends, studying economic phenomena, social science problems, etc.\n",
    "- Cohort analysis is a particularly illuminating application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"trends-and-seasonality\"></a>\n",
    "### Trends and Seasonality\n",
    "Typically, we are interested in separating the effects of time into two components:\n",
    "- **Trends** - significant increases or decreases over time\n",
    "- **Seasonality** - regularly repeating increases or decreases\n",
    "- Although, there are many more time related questions that can be asked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following plot of fireworks injury rates from FiveThirtyEight, we can see there is an overall trend of fewer injuries with no seasonal pattern.\n",
    "\n",
    "![](assets/images/munguia-datalab-fireworks2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, many other phenomena may be entirely seasonal. If we look at the number of searches for the New Hampshire Primary, we can see that there are clear spikes every four years and on election years.\n",
    "![](assets/images/google-nh.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, searches for ‘gingerbread houses’ spike every year around the holiday season.\n",
    "\n",
    "![](assets/images/google-gingerbread.png)\n",
    "\n",
    "These spikes recur on a fixed time-scale, making them seasonal patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"other-time-phenomena\"></a>\n",
    "### Other time phenomena\n",
    "Many other types of regularly occurring up or down swings may occur without a fixed timescale or period (e.g. growth vs. recession for economic trends).\n",
    "\n",
    "- These aperiodic patterns are called cycles.\n",
    "- While identifying aperiodic cycles is important, they are often treated differently than seasonal effects in practice.  \n",
    "- Seasonal effects are useful for their consistency, since prior data is useful as a predictor.\n",
    "- You may also see one-time spikes or transitory shocks that can be useful to capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searches for “iphone” have both a general trend upwards (indicating more popularity for the phone) as well as a seasonal spike in September (which is when Apple typically announces new versions).\n",
    "\n",
    "![iphone](assets/google-iphone.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We decompose the times series into these more understandable pieces**\n",
    "- Therefore it is important to identify whether we think a change is due to an ongoing trend or seasonal change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo-exploring-rossmann-drugstore-sales-data\"></a>\n",
    "## Demo: Exploring Rossmann drugstore sales data\n",
    "Objective: Perform time series analysis in Pandas including rolling mean/median and autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using data made available by a German drugstore, Rossmann.\n",
    "\n",
    "This data contains the daily sales made at the drugstore as well as whether there was a sale or holiday affecting the sales data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load-dataset-and-pre-process\"></a>\n",
    "### Load Dataset and Pre-Process\n",
    "\n",
    "We will use the [Rossmann Store Sales](https://www.kaggle.com/c/rossmann-store-sales) dataset.  \n",
    "\n",
    "Data Dictionary from Kaggle  \n",
    "\n",
    "You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.\n",
    "\n",
    "Most of the fields are self-explanatory. The following are descriptions for those that aren't.\n",
    "\n",
    "* Id - an Id that represents a (Store, Date) duple within the test set\n",
    "* **Store** - a unique Id for each store\n",
    "* **Sales** - the turnover for any given day (this is what you are predicting)\n",
    "* **Customers** - the number of customers on a given day\n",
    "* **Open** - an indicator for whether the store was open: 0 = closed, 1 = open\n",
    "* **StateHoliday** - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
    "* **SchoolHoliday** - indicates if the (Store, Date) was affected by the closure of public schools\n",
    "* StoreType - differentiates between 4 different store models: a, b, c, d\n",
    "* Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
    "* CompetitionDistance - distance in meters to the nearest competitor store\n",
    "* CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
    "* **Promo** - indicates whether a store is running a promo on that day\n",
    "* Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
    "* Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
    "* PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As always, use Pandas to load our data.\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5)\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "\n",
    "data = pd.read_csv('./data/rossmann.csv', skipinitialspace=True, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we are most interested in the Date column, \n",
    "# we can process it as a DateTime type and set it as the index of our dataframe.\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "data['Year'] = data.index.year\n",
    "data['Month'] = data.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This allows us to easily filter by date.  For example, to a particular year:\n",
    "data['2014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also filter to a particular month:\n",
    "data['2015-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are over a million sales data points in this dataset, so for some analysis we will focus on just one store.\n",
    "store1_data = data[data.Store == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting the sales data**\n",
    "\n",
    "As we begin to study the sales from this drug store, we will also want  to know both the time dependent elements of sales as wells as whether promotions or holidays affected sales.\n",
    "\n",
    "To start, we can simply compare the average sales on those events.\n",
    "\n",
    "To compare sales on holidays, we can compare the sales using box plots.  This allows us to compare the distribution of sales on holidays against all other days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On state holidays the store is closed (so there should be 0 sales).\n",
    "# On school holidays, the sales are relatively similar.\n",
    "\n",
    "sns.factorplot(\n",
    "    col='Open',\n",
    "    x='SchoolHoliday',\n",
    "    y='Sales',\n",
    "    data=store1_data, \n",
    "    kind='box'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if there is a difference affecting sales on promotion days.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sales vs promotion days\n",
    "### FILL IN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see there is a difference in sales on promotion days.\n",
    "\n",
    "sns.factorplot(\n",
    "    col='Open',\n",
    "    x='Promo',\n",
    "    y='Sales',\n",
    "    data=store1_data, \n",
    "    kind='box'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is it important to separate out days where the store is closed?**\n",
    "\n",
    "<!--\n",
    "- Because there aren’t any promotions on those days either, so including them will bias your sales data on days without promotions.\n",
    "- In other words, the two factors are correlated\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let’s compare sales across days of the week.  \n",
    "\n",
    "sns.factorplot(\n",
    "    col='Open',\n",
    "    x='DayOfWeek',\n",
    "    y='Sales',\n",
    "    data=store1_data,\n",
    "    kind='box',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, we want to identify larger scale trends in our data.\n",
    "# How did sales change from 2014 to 2015?  Were any particularly interesting outliers in terms of sales or customer visits?\n",
    "\n",
    "#To plot the sales over time:\n",
    "\n",
    "# Filter to days store 1 was open\n",
    "store1_open_data = store1_data[store1_data.Open==1]\n",
    "store1_open_data[['Sales']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot customer visits over time over time:\n",
    "\n",
    "store1_open_data[['Customers']].plot()\n",
    "\n",
    "#We can see that there are large spikes of sales and customers towards the end of 2013 and 2014 leading into the first quarter of 2014 and 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter to just 2014 and plot the customer data. Is it easier to identify the holiday sales bump?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot *sales* over time for *2014*\n",
    "### FILL IN ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction-common-analysis-for-time-series-data\"></a>\n",
    "## Introduction: Common analysis for time series data\n",
    "Objective: Identify and apply common transformation of time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"aggregating-time-series\"></a>\n",
    "### Aggregating time series\n",
    "If we want to investigate trends over time in sales, we will start by computing simple aggregations. What were the mean and median sales in each year and each month?\n",
    "\n",
    "In Pandas, this is performed using the resample method, which is very similar to the groupby method.  It allows us to group over different time periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is where Pandas gets awesome**\n",
    "\n",
    "We've mostly done very simple exploratory data analysis in class when using Pandas, this is not a great way to showcase Pandas. \n",
    "\n",
    "What is nice about Pandas is that when we start doing many custom computations and deal with more complicated topics, Pandas does not become much more complicated to use if we know the built in shortcuts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use data.resample and provide the following arguments:**\n",
    "- A level on which to roll up to:  ‘D’ for day, ‘W’ for week, ‘M’ for month, ‘A’ for year.\n",
    "- The aggregation to perform:  ‘mean’, ‘median’, ‘sum’, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Sales']].resample('A').apply(['median', 'mean']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Sales']].resample('M').apply(['median', 'mean']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that December 2013 and 2014 were the highest average sales months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Sales']].resample('M').apply(['median', 'mean']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pandas-window-functions\"></a>\n",
    "### Pandas window functions\n",
    "\n",
    "Pandas rolling.mean and rolling.median are examples of Pandas window function capabilities.\n",
    "\n",
    "Window functions operate on a set of N consecutive rows (a window) and produce output.\n",
    "\n",
    "In addition, there are rolling.sum, rolling.min, rolling.max, and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**rolling takes three important parameters: **\n",
    "- window is the number of days to include in the average \n",
    "- center is whether the window should be centered on the date or use data prior to that date \n",
    "- freq is on what level to roll-up the averages to (as used in resample). Either D for day, M for month or A for year, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another common window function is diff, which takes differences over time.**\n",
    "\n",
    "Differencing a time series is a very useful way to remove long-term time trends.\n",
    "\n",
    "pd.diff takes one argument, periods, which is how many rows prior to use for the difference.\n",
    "\n",
    "For example, if we want to compute the difference in sales, day by day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sales'].resample('D').mean().diff(periods=1).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we wanted to compare the same day in the prior week, we could set periods=7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sales'].resample('D').mean().diff(periods=7).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would compute the difference in sales, from every day to the same day in the previous week.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What would happen if we did not use resample in the above example?**\n",
    "\n",
    "Hint: Sometimes it would work and sometimes it would fail\n",
    "    \n",
    "Why?\n",
    "\n",
    "<!--\n",
    "- It's possible to have to events occur at the same time. \n",
    "- How would you compute a rolling function in that case?\n",
    "- One might consider averaging the two events, but that's the same a resampling/aggregting first\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following plot of the month to month change (diff) in jobs from FiveThirtyEight helps identify the seasonal component to a number of retail jobs:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/images/casselman-datalab-wsj2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pandas-expanding-functions\"></a>\n",
    "### Pandas expanding functions\n",
    "\n",
    "In addition to the set of “rolling” functions, Pandas also provides a similar set of “expanding” functions.\n",
    "\n",
    "Instead of using a window of N values, “expanding” functions use all values up until that time. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the average sales from the first date until the date specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Sales']].resample('D').mean().expanding().mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the sum of average sales per store up until that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Sales']].resample('D').mean().expanding().sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Sales']].resample('D').mean().rolling(window=10, center=True).mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This averages all values in the window evenly. However we may want to weight closer values more.\n",
    "\n",
    "For example, for a centered weighted average of 10 days, we want to put emphasis on +/- 1 day versus +/- 5 days.\n",
    "\n",
    "One option to do that is the ewma function or the exponential weighted moving average function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"moving-averages\"></a>\n",
    "###  Moving Averages\n",
    "\n",
    "- A moving average replaces each data point with an average of k consecutive data points in time.\n",
    "- Typically, this is k/2 data points prior to and following a given time point, but it could also be the k preceding points.\n",
    "- These are often referred to as the “rolling” average.\n",
    "- The measure of average could be mean or median.\n",
    "- The formula for the rolling mean is\n",
    "\n",
    "$$F_t = \\frac{1}{p} \\sum_{k=t}^{t-p+1} Y_k$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store1_data['2015-05']['Sales'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of plotting the original time series, we can plot the rolling mean instead.  This smooths random changes in sales as well as removing outliers, helping us identify larger trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Sales']].resample('D').mean().rolling(window=3, center=True).mean()['2015-05'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Sales']].resample('D').mean().rolling(window=7, center=True).mean()['2015-05'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What would a moving (rolling) mean indicate vs. a moving (rolling) median?**\n",
    "\n",
    "<!--\n",
    "- They would both be measures of central tendency over time\n",
    "- The median would be more sensitive to outliers as usual\n",
    "- A rolling mean would average all values in the window, but can be skewed by outliers (extremely small or large values).\n",
    "- This may be useful if we are looking to identify atypical periods or we want to evaluate these odd periods.\n",
    "- For example, this would be useful if we are trying to identify particularly successful or unsuccessful sales days.\n",
    "- The rolling median would provide the 50 percentile value for the period and would possibly be more representative of a “typical” day.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This plot shows the 30-day moving average of the Economic Uncertainty Index.**\n",
    "\n",
    "Plotting the moving average allows us to more easily visualize trends by smoothing out random fluctuations and removing outliers.\n",
    "\n",
    "![](assets/images/flowers-datalab-policy-2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**While identifying the monthly averages is useful, we often want to compare time series data in a local time window.**\n",
    "\n",
    "To understand holiday sales, we want to compare the sales data of late December to a few days surrounding it.  \n",
    "\n",
    "We can do this using rolling averages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, we can compute the rolling average using the pd.rolling_mean or pd.rolling_median functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "december_sales = data['2014-12'][['Sales']].resample(rule='D').mean().copy()\n",
    "december_sales['2_day_sales'] = december_sales.rolling(window=2, center=True).mean()\n",
    "december_sales['2_day_spikes'] = december_sales['Sales'] - december_sales['2_day_sales']\n",
    "december_sales[['Sales','2_day_sales']].plot()\n",
    "december_sales[['2_day_spikes']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we would expect, there is a weekly spike as we transition from the weekend to the weekday. In this case, we can also see there is a holiday spike."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exponential-weighted-moving-averages\"></a>\n",
    "### Exponential Weighted Moving Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taking proximity into account**\n",
    "- While simple rolling functions weigh all data evenly, it may make sense to weight data closer to our date of interest higher.\n",
    "- We do this by taking a weighted moving average, where we assign particular weights to certain time points.\n",
    "- Various formulas or schemes can be used to weight the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common weighting scheme is an exponential weighted moving average (EWMA) where we add a decay term to give less and less weight to older data points.\n",
    "\n",
    "The EWMA can be calculated recursively for a series Y.\n",
    "\n",
    "For t = 1, \n",
    "$$EWMA_1 = Y_1$$\n",
    "\n",
    "For t > 1, \n",
    "$$EWMAt = \\alpha * Y_t + (1 - \\alpha) * EWMA_{t-1}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sales'].ewm(span=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"autocorrelation\"></a>\n",
    "## Autocorrelation\n",
    "Objective: Define autocorrelation and use it to analyze a dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous classes, we have been concerned with how two variables are correlated (e.g. height and weight, education and salary).\n",
    "\n",
    "Autocorrelation is how correlated a variable is with itself. Specifically, how related are variables earlier in time with variables later in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"why-can-autocorrelation-be-a-problem\"></a>\n",
    "### Why can autocorrelation be a problem?\n",
    "\n",
    "- When we talked about multi-collinearity, we said that coefficients will be mis-estimated or that they will attribute the explanatory effect to the wrong variables.\n",
    "- Autocorrelation can pose similar issues\n",
    "- Typically it's sufficient to know that there is no long-term autocorrelation in your data\n",
    "  - http://stats.stackexchange.com/questions/19715/why-does-a-time-series-have-to-be-stationary\n",
    "- Similarly to multi-collinearity, this does not pose as much of an issue when focusing on prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"how-to-compute-autocorrelation\"></a>\n",
    "### How to compute autocorrelation\n",
    "\n",
    "- To compute autocorrelation, we fix a “lag” k.\n",
    "  - This is how many time points earlier we should use to compute the correlation.\n",
    "\n",
    "- A lag of 1 computes how correlated a value is with the prior one.  - A lag of 10 computes how correlated a value is with one 10 time points earlier.\n",
    "- The following formula can be used to calculate autocorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$r_k = \\frac {\\sum_{t = k + 1}^n {(y_t-\\bar{y})(y_{t-k}-\\bar{y})}} {\\sum_{t = 1}^n {(y_t - \\bar {y})^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**key features:**\n",
    "- This a lot like normal correlation\n",
    "- You can think of this as correlation between two variables, $y_t$ and $y_{t-k}$\n",
    "- $y_t$ is the usual feature that you are working with\n",
    "- $y_{t-k}$ is the same feature lagged or shifted by some amount of time\n",
    "- We take the correlation of a variables against its own time-delayed version, hence autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What would a highly autocorrelated timeseries variable look like?**\n",
    "\n",
    "<!--\n",
    "We are looking for data that 'echos' itself in some way. By definition we are looking for a signal that repeats itself with some lag or lead. This could be an exact repetition like seasonality or something that shows a similar structure like a linear trend.\n",
    "\n",
    "Notice that this means trends and seasonality will show autocorrelation\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_plot(store1_data['2015-05']['Sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation plots are often used for checking randomness in time series. This is done by computing autocorrelations for data values at varying time lags. If time series is random, such autocorrelations should be near zero for any and all time-lag separations. If time series is non-random then one or more of the autocorrelations will be significantly non-zero. The horizontal lines displayed in the plot correspond to 95% and 99% confidence bands. The dashed line is 99% confidence band. See the Wikipedia entry for more about autocorrelation plots.\n",
    "\n",
    "Values on or outside of each line are very likely a correlation and not a statistical fluke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Autocorrelation**: Is the degree of correlation\n",
    "- **Lag**: Is the number of time periods between the current observation and past observation\n",
    "\n",
    "Notice the the first spike in correlation for a 7 day lag. Why does this happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "plot_acf(store1_data.Sales, lags=21);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Autocorrelation\n",
    "\n",
    "In time series analysis, the partial autocorrelation function (PACF) gives the partial correlation of a time series with its own lagged values, controlling for the values of the time series at all shorter lags. It contrasts with the autocorrelation function, which does not control for other lags.\n",
    "\n",
    "[Partial Autocorrelation](https://en.wikipedia.org/wiki/Partial_autocorrelation_function)\n",
    "\n",
    "You may have noticed that seasonal effects tend to reoccur in an autocorrelation plot. What if we want to look at a 14 day lag, while accounting for the 7 day affect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(store1_data.Sales, lags=21);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"exercises\"></a>\n",
    "<a id=\"exercises\"></a>\n",
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the distribution of sales by month and compare the effect of promotions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are sales more correlated with the prior date, a similar date last year, or a similar date last month?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the 15 day rolling mean of customers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identify the date with largest drop in sales from the same date in the previous week.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the total sales up until Dec. 2014.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When were the largest differences between 15-day moving/rolling averages?  HINT:  Using rolling_mean and diff**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC REVIEW\n",
    "\n",
    "- What are some unique challenges of time series?\n",
    "<!--\n",
    "Hard to calculate\n",
    "More opportunities for unwanted correlation\n",
    "-->\n",
    "- What were the two most common decompositions that we want to identify in time series data?\n",
    "<!-- We want to identify whether changes are true trends or seasonal changes. -->\n",
    "- Why do we bother to use rolling means or medians?\n",
    "<!-- \n",
    "Rolling means give us a local statistic of an average in time, smoothing out random fluctuations and removing outliers. -->\n",
    "- What is autocorrelation?\n",
    "<!-- Autocorrelations are a measure of how much a data point is dependent on previous data points. -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
