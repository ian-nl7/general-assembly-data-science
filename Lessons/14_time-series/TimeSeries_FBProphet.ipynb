{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Working With Time Series Data in FBProphet\n",
    "\n",
    "_By Steven Longstreet (Washington DC) and Bryce Peake (Washington DC)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    " \n",
    "**After this lesson, you will be able to:**\n",
    "- Identify time series data.\n",
    "- Explain the challenges of working with time series data.\n",
    "- Use the `datetime` library to represent dates as objects.\n",
    "- Preprocess time series data with Pandas\n",
    "- Create and visualize a Time Series model using FBProphet\n",
    "- Evaluate a Time Series model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"A\">What is a Time Series?</a></h2>\n",
    "A **time series** is a series of data points that's indexed (or listed, or graphed) in time order. Most commonly, a time series is a sequence that's taken at successive equally spaced points in time. Time series are often represented as a set of observations that have a time-bound relation, which is represented as an index.\n",
    "\n",
    "Time series are commonly found in sales, analysis, stock market trends, economic phenomena, and social science problems.\n",
    "\n",
    "These data sets are often investigated to evaluate the long-term trends, forecast the future, or perform some other form of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at some Apple stock data to get a feel for what time series data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:37:06.357588Z",
     "start_time": "2019-09-09T13:37:06.329663Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n",
    "\n",
    "apple_stock = pd.read_csv(\"./data/aapl.csv\")\n",
    "apple_stock.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"B\">The DateTime library</a></h2>\n",
    "As time is important to time series data, we will need to interpret these data in the ways that humans interpret them (which is many ways). \n",
    "\n",
    "Python's `DateTime` library is great for dealing with time-related data, and Pandas has incorporated this library into its own `datetime` series and objects.\n",
    "\n",
    "In this lesson, we'll review these data types and learn a little more about each of them:\n",
    "\n",
    "* `datetime` objects.\n",
    "* `datetime` series.\n",
    "* Timestamps.\n",
    "* `timedelta()`.\n",
    "\n",
    "### `datetime` Objects\n",
    "Below, we'll load in the `DateTime` library, which we can use to create a `datetime` object by entering in the different components of the date as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:37:09.149445Z",
     "start_time": "2019-09-09T13:37:09.145455Z"
    }
   },
   "outputs": [],
   "source": [
    "# The datetime library is something you should already have from Anaconda.\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:37:11.202926Z",
     "start_time": "2019-09-09T13:37:11.197940Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's just set a random datetime — not the end of the world or anything.\n",
    "lesson_date = datetime(2012, 12, 21, 12, 21, 12, 844089)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:37:12.648016Z",
     "start_time": "2019-09-09T13:37:12.638043Z"
    }
   },
   "outputs": [],
   "source": [
    "#The components of the date are accessible via the object's attributes.\n",
    "print(\"Micro-Second\", lesson_date.microsecond)\n",
    "print(\"Second\", lesson_date.second)\n",
    "print(\"Minute\", lesson_date.minute)\n",
    "print(\"Hour\", lesson_date.hour)\n",
    "print(\"Day\", lesson_date.day)\n",
    "print(\"Month\",lesson_date.month)\n",
    "print(\"Year\", lesson_date.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `timedelta()`\n",
    "Suppose we want to add time to or subtract time from a date. Maybe we're using time as an index and want to get everything that happened a week before a specific observation.\n",
    "\n",
    "We can use a `timedelta` object to shift a `datetime` object. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:37:14.769837Z",
     "start_time": "2019-09-09T13:37:14.761859Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import timedelta() from the DateTime library.\n",
    "from datetime import timedelta\n",
    "\n",
    "# Timedeltas represent time as an amount rather than as a fixed position.\n",
    "offset = timedelta(days=1, seconds=20)\n",
    "\n",
    "# The timedelta() has attributes that allow us to extract values from it.\n",
    "print('offset days', offset.days)\n",
    "print('offset seconds', offset.seconds)\n",
    "print('offset microseconds', offset.microseconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`datetime`'s `.now()` function will give you the `datetime` object of this very moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:37:17.164505Z",
     "start_time": "2019-09-09T13:37:17.160515Z"
    }
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "print(\"Like Right Now: \", now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current time is particularly useful when using `timedelta()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:37:20.754045Z",
     "start_time": "2019-09-09T13:37:20.748057Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Future: \", now + offset)\n",
    "print(\"Past: \", now - offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: The largest value a `timedelta()` can hold is days. For instance, you can't say you want your offset to be two years, 44 days, and 12 hours; you have to convert those years to days.*\n",
    "\n",
    "You can read more about the `timedelta()` category [here](https://docs.python.org/2/library/datetime.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T17:47:52.977683Z",
     "start_time": "2019-01-02T17:47:52.973677Z"
    }
   },
   "source": [
    "## Preprocessing Time Series Data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T17:49:08.091220Z",
     "start_time": "2019-01-02T17:49:07.974402Z"
    }
   },
   "outputs": [],
   "source": [
    "#Overwrite the original `Date` column with one that's been converted to a `datetime` series.\n",
    "apple_stock['Date'] = pd.to_datetime(apple_stock.Date)\n",
    "apple_stock.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `.dt` Attribute\n",
    "Pandas' `datetime` columns have a `.dt` attribute that allows you to access attributes that are specific to dates. For example:\n",
    "\n",
    "    aapl.Date.dt.day\n",
    "    aapl.Date.dt.month\n",
    "    aapl.Date.dt.year\n",
    "    aapl.Date.dt.weekday_name\n",
    "\n",
    "Check out the Pandas `.dt` [documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.dt.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_stock.Date.dt.weekday_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_stock.Date.dt.dayofyear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestamps\n",
    "Timestamps are useful objects for comparisons. You can create a timestamp object using the `pd.to_datetime()` function and a string specifying the date. These objects are especially helpful when you need to perform logical filtering with dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T17:50:54.674698Z",
     "start_time": "2019-01-02T17:50:54.665671Z"
    }
   },
   "outputs": [],
   "source": [
    "ts = pd.to_datetime('1/1/2017')\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The main difference between a `datetime` object and a timestamp is that timestamps can be used as comparisons.\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_stock.loc[apple_stock.Date >= ts, :].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by date with Pandas\n",
    "It is easy to filter by date using Pandas. Let's create a subset of data containing only the stock prices from 2017. We can specify the index as a string constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, set the date (as a datetime obj) as the index\n",
    "apple_stock.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can ask for only that data from December 2016\n",
    "apple_stock['2016-12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things to note about indexing with time series. Unlike numeric indexing, the end index will be included. If you want to index with a range, the time indices must be sorted first.  \n",
    "\n",
    "> **Recap:** The steps for preprocessing time series data are to:\n",
    "* Convert time data to a `datetime` object.\n",
    "* Set `datetime` to index the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Practice\n",
    "Let's use the UFO data set to build a timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T17:55:12.039745Z",
     "start_time": "2019-01-02T17:55:12.036737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a `datetime` object representing today's date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the UFO data set from the internet.\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n",
    "\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Time column to a datetime object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the `Time` column to the index of the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a `timestamp` object for the date January 1, 1999.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of entries with a date above or equal to January 1, 1999 using a timestamp object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series modeling with FBProphet\n",
    "You will need to install prophet for this notebook. While we've used `pip install` in the past, it often causes errors. So, in terminal, we'll use an alternative: `conda install -c conda-forge fbprophet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T13:51:16.162545Z",
     "start_time": "2019-09-09T13:51:16.131627Z"
    }
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Temp\\\\tmpagvimn81\\\\stanfit4anon_model_db8febf10f23d7fa27a62fbcfd7f17b2_604436787436303341.cp37-win_amd64.pyd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b03483de9997>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProphet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\fbprophet\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# of patent rights can be found in the PATENTS file in the same directory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforecaster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProphet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'0.5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\fbprophet\\forecaster.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagnostics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprophet_copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_holidays\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_holiday_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmake_holidays_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprophet_stan_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m from fbprophet.plot import (plot, plot_components, plot_forecast_component,\n\u001b[0;32m     23\u001b[0m                             \u001b[0mplot_seasonality\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_weekly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_yearly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\fbprophet\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mprophet_stan_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_prophet_stan_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\fbprophet\\models.py\u001b[0m in \u001b[0;36mget_prophet_stan_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     )\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pystan\\model.py\u001b[0m in \u001b[0;36m__setstate__\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[0mlib_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdtemp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Temp\\\\tmpagvimn81\\\\stanfit4anon_model_db8febf10f23d7fa27a62fbcfd7f17b2_604436787436303341.cp37-win_amd64.pyd'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fbprophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "%matplotlib inline\n",
    " \n",
    "plt.rcParams['figure.figsize']=(20,10)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data\n",
    "\n",
    "Read the data in from the retail sales CSV file in the examples folder then set the index to the 'date' column. We are also parsing dates in the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('../data/retail_sales.csv', parse_dates = True, low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Prophet\n",
    "\n",
    "For prophet to work, we need to change the names of these columns to 'ds' and 'y', so lets just create a new dataframe and keep our old one handy (you'll see why later). The new dataframe will initially be created with an integer index so we can rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.rename(columns={'date':'ds', 'sales':'y'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now's a good time to take a look at your data.  Plot the data using pandas' ```plot``` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.set_index('ds').y.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with time-series data, its good to take a look at the data to determine if trends exist, whether it is stationary, has any outliers and/or any other anamolies. Facebook prophet's example uses the log-transform as a way to remove some of these anomolies but it isn't the absolute 'best' way to do this...but given that its the example and a simple data series, I'll follow their lead for now.  Taking the log of a number is easily reversible to be able to see your original data. \n",
    "\n",
    "To log-transform your data, you can use numpy's log() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['y'] = np.log(sales_df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.set_index('ds').y.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the above chart, the plot looks the same as the first one but just at a different scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Prophet\n",
    "\n",
    "Now, let's set prophet up to begin modeling our data.\n",
    "\n",
    "Note: Since we are using monthly data, you'll see a message from Prophet saying ```Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.```  This is OK since we are workign with monthly data but you can disable it by using ```weekly_seasonality=True``` in the instantiation of Prophet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prophet()\n",
    "model.fit(sales_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecasting is fairly useless unless you can look into the future, so we need to add some future dates to our dataframe. For this example, I want to forecast 2 years into the future, so I'll built a future dataframe with 24 periods since we are working with monthly data. Note the ```freq='m'``` inclusion to ensure we are adding 24 months of data.\n",
    "\n",
    "This can be done with the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = model.make_future_dataframe(periods=24, freq = 'm')\n",
    "future.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To forecast this future data, we need to run it through Prophet's model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = model.predict(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting forecast dataframe contains quite a bit of data, but we really only care about a few columns.  First, let's look at the full dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We really only want to look at yhat, yhat_lower and yhat_upper, so we can do that with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Prophet results\n",
    "\n",
    "Prophet has a plotting mechanism called ```plot```.  This plot functionality draws the original data (black dots), the model (blue line) and the error of the forecast (shaded blue area)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Prophet\n",
    "The shaded blue area is the error of the forecast. But we can only eyeball it. Let's look at the R-squared (amount of variance) and Mean Squared Error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do this, we have to get the y-hat and original y's from the data\n",
    "metric_df = forecast.set_index('ds')[['yhat']].join(sales_df.set_index('ds').y).reset_index()\n",
    "metric_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T14:09:07.844976Z",
     "start_time": "2019-01-02T14:09:07.841993Z"
    }
   },
   "outputs": [],
   "source": [
    "# The tail has NaN values, because they're predictions - there was no real Y. Let's drop those for model evaluation.\n",
    "metric_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at the numbers\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "print(\"R-squared: \", r2_score(metric_df.y, metric_df.yhat))\n",
    "print(\"Mean Squared Error: \", mean_squared_error(metric_df.y, metric_df.yhat))\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(metric_df.y, metric_df.yhat)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An R2 value of .99 is phenomenal... and too good to be true. Our massive MSE confirms any suspcion tha thte model is overfit and won't be very predictive in the future. Part of the problem in this example is that the its monthly, and there aren't enough data points to build a robust model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Accounting for Seasonality and Trends\n",
    "\n",
    "We can see from this data that there is a spike in the same month each year. While spike could be due to many different reasons, let's assume its because there's a major promotion that this company runs every year at that time, which is in December for this dataset.\n",
    "\n",
    "When patterns repeat over *known, fixed periods* of time within a data set, we call this **seasonality**. A seasonal pattern exists when a series is influenced by factors related to the cyclic nature of time — i.e., time of month, quarter, year, etc. Seasonality is of a fixed and known period, otherwise it is not truly seasonality. Additionally, it must be either attributed to another factor or counted as a set of anomalous events in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet calls them \"holidays\"\n",
    "\n",
    "Because we know this promotion occurs every december, we want to use this knowledge to help prophet better forecast those months, so we'll use prohpet's ```holiday``` construct (explained here https://facebookincubator.github.io/prophet/docs/holiday_effects.html).\n",
    "\n",
    "The holiday object is a pandas dataframe with the holiday and date of the holiday. For this example, the construct would look like this:\n",
    "\n",
    "```promotions = pd.DataFrame({\n",
    "  'holiday': 'december_promotion',\n",
    "  'ds': pd.to_datetime(['2009-12-01', '2010-12-01', '2011-12-01', '2012-12-01',\n",
    "                        '2013-12-01', '2014-12-01', '2015-12-01']),\n",
    "  'lower_window': 0,\n",
    "  'upper_window': 0,\n",
    "})```\n",
    "\n",
    "This ```promotions``` dataframe consisists of promotion dates for Dec in 2009 through 2015,  The ```lower_window``` and ```upper_window``` values are set to zero to indicate that we don't want prophet to consider any other months than the ones listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-02T13:49:17.379531Z",
     "start_time": "2019-01-02T13:49:17.375510Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the promotions dataframe from above here - be sure you understand the syntax and logic!\n",
    "promotions = pd.DataFrame({\n",
    "  'holiday': 'december_promotion',\n",
    "  'ds': pd.to_datetime(['2009-12-01', '2010-12-01', '2011-12-01', '2012-12-01',\n",
    "                        '2013-12-01', '2014-12-01', '2015-12-01']),\n",
    "  'lower_window': 0,\n",
    "  'upper_window': 0,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, we need to log-transform for prophet\n",
    "sales_df['y'] = np.log(sales_df['y'])\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's set up prophet to model our data using holidays\n",
    "model = Prophet(holidays=promotions)\n",
    "model.fit(sales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We've instantiated the model, so now we need to build our future dates to forecast into!\n",
    "future = model.make_future_dataframe(periods=24, freq = 'm')\n",
    "future.tail()\n",
    "\n",
    "#... and then run our future data through prophet's model\n",
    "forecast = model.predict(future)\n",
    "\n",
    "forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#while our new df contains a bit of data, we only care about a few features...\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing with holidays!\n",
    "Same as above at first blush!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Prophet's .plot() method to visualize your timeseries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prophet also allows you to examine the ```components``` of a timeseries using the ```.plot_components()``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_components(forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why holidays matter\n",
    "Let's re-run our prophet model without holidays, for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_holiday = Prophet()\n",
    "model_no_holiday.fit(sales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_no_holiday = model_no_holiday.make_future_dataframe(periods=24, freq = 'm')\n",
    "future_no_holiday.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_no_holiday = model_no_holiday.predict(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There probably won't be a massive difference, given the small amount of data with which we're working on this example. But with greater data comes greater variance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the dataframes\n",
    "forecast.set_index('ds', inplace=True)\n",
    "forecast_no_holiday.set_index('ds', inplace=True)\n",
    "compared_df = forecast.join(forecast_no_holiday, rsuffix=\"_no_holiday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we're only interested in the predictions, and let's move back to the original scale\n",
    "compared_df= np.exp(compared_df[['yhat', 'yhat_no_holiday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature that is the percentage difference between holiday vs. none\n",
    "compared_df['diff_per'] = 100 * (compared_df['yhat'] - compared_df['yhat_no_holiday']) / compared_df['yhat_no_holiday']\n",
    "print(\"difference: \", round(compared_df.diff_per.mean(), 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the difference here is less than 1%, that can be a large amount of money left on the table if your business is a global enterprise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet for Market prediction - lab time!\n",
    "Prophet can detect changepoints in timeseries data, and we can often use it to our advantage. Let's grab FRED economic data and see how this goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download 01/2009 - current S&P500 data at https://fred.stlouisfed.org/series/SP500 and import it into pandas\n",
    "market_df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now prepare your data for prophet. Hint: prophet needs \"ds\" and a log-transformed \"y\" to work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the model, and fit our data\n",
    "model = Prophet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the future dataframe, forecasting for 1 year from now. THen create a forecast by passing the future into model.predict()\n",
    "future = model.make_future_dataframe(periods = 365)\n",
    "forecast = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now plot it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to see what's going on here, in part because we have such a condensed visual. Let's look at the last 2 years of forecast vs. actual without looking at the future - we are just interested ing etting a visual of theerror between actual vs. forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start by setting the index of the forecast df to the ds, and joining it to the marekt_df\n",
    "two_years = \n",
    "\n",
    "#now set two_years equal to the last 800 data points\n",
    "two_years = two_years[['SP500', 'yhat', 'yhat_upper', 'yhat_lower' ]].dropna().tail(800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now trasnform the predictions back to the original scale of the data\n",
    "two_years['yhat']=np.exp(two_years.yhat)\n",
    "two_years['yhat_upper']=np.exp(two_years.yhat_upper)\n",
    "two_years['yhat_lower']=np.exp(two_years.yhat_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's visualize the relationship between SP500 and yhat (our prediction) using pandas .plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our forecast does great at trending, but doesn't do well at catching the volatility of the market. This would be very good for 'riding trends', but not so good for catching peaks and dips. \n",
    "\n",
    "We can see this in the numbers as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to tlook at the usefulness of this forecast is to plot the upper and lower confidence bands against the actuals. We can do that with a plot that combines yhat_upper and yhat_lower with the rest into a matplotlib subplot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(two_years.SP500)\n",
    "ax1.plot(two_years.yhat)\n",
    "ax1.plot(two_years.yhat_upper, color='black',  linestyle=':', alpha=0.5)\n",
    "ax1.plot(two_years.yhat_lower, color='black',  linestyle=':', alpha=0.5)\n",
    "\n",
    "ax1.set_title('Actual S&P 500 (Orange) vs S&P 500 Forecasted Upper & Lower Confidence (Black)')\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.set_xlabel('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above, if you're trying to do shortterm trading then this model is useless. But if you are investing with a timeframe of months to years, this forecast might provide some value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also look at this from the full df. Here I build it manually again!\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(full_df.SP500)\n",
    "ax1.plot(full_df.yhat, color='black', linestyle=':')\n",
    "ax1.fill_between(full_df.index, np.exp(full_df['yhat_upper']), np.exp(full_df['yhat_lower']), alpha=0.5, color='darkgray')\n",
    "ax1.set_title('Actual S&P 500 (Orange) vs S&P 500 Forecasted (Black) with Confidence Bands')\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.set_xlabel('Date')\n",
    "\n",
    "L=ax1.legend() #get the legend\n",
    "L.get_texts()[0].set_text('S&P 500 Actual') #change the legend text for 1st plot\n",
    "L.get_texts()[1].set_text('S&P 5600 Forecasted') #change the legend text for 2nd plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
